# agent_006 Benchmark Results

**Symbol:** COINBASE_SPOT_BTC_USD
**Start Time:** 2026-01-04T01:05:00.673Z
**Progress:** Round 3/12 (Phase 0)
**Last Updated:** 2026-01-04T01:14:52.249Z

## Benchmark Overview

This benchmark evaluates LLMs on a **binary classification task** across 4 horizons (15m, 1h, 4h, 24h):

> For each horizon, predict whether the current reference low will hold (*no new low*) or be undercut within the forward window.

**Label definition (`noNewLow`):**
- `1` (true): Forward window low â‰¥ reference low (bottom held)
- `0` (false): Forward window low < reference low (new low made)

**Horizons** share the same symbol and time but differ in bar size, lookback window, and forward prediction window.

## Methodology

### Ground Truth
- **Reference low**: Minimum low price across lookback candles
- **Forward low**: Minimum low price in the forward window (prediction horizon)
- **Label**: `y = 1` if forward low â‰¥ reference low, else `y = 0`

### Probability Mapping
Models output `{ noNewLow: boolean; confidence âˆˆ [0.5, 1.0] }` per horizon.
- Probability of no new low: `p = noNewLow ? confidence : (1 - confidence)`

### Scoring
- **Log loss** (primary): `LL = -(yÂ·log(p) + (1âˆ’y)Â·log(1âˆ’p))`, with p clipped to [Îµ, 1âˆ’Îµ]
- **Random baseline**: p=0.5 gives LL â‰ˆ 0.693
- **Brier score**: Used in Phase 0 sanity checks only (not shown in tables)

### Phases & Elimination
- **Phase 0 â€“ Sanity filter**: Disqualifies horizons where model performs worse than random baseline, shows degenerate predictions (all mapped p â‰¥ 0.9 or p â‰¤ 0.1), or has high extreme error rate (>20% confidently wrong)
- **Phase 1 â€“ Percentile filter**: Retains models above performance threshold per horizon
- **Phase 2 â€“ Stability filter**: Evaluates consistency using rolling windows; eliminates models with no qualified horizons remaining
- **Phase 3 â€“ Final ranking**: Composite scoring of surviving models

> **Quick mode note:** This verification run only calculates raw log loss per horizon. Full Phase 0â€“3 elimination is applied in the complete benchmark only.

**Status codes:**
- `âœ… Active`: Survived all phases with â‰¥1 qualified horizon
- `âŒ P0`: Eliminated in Phase 0 (all horizons failed sanity checks)
- `âŒ P2`: Eliminated in Phase 2 (no qualified horizons remaining)

## Summary

- **Active Models:** 28
- **Eliminated:** 0
- **Models with Failures:** 9

## Full Results (All Models)

| Rank | Model | Status | Rnds | 15m | 1h | 4h | 24h | Mean | %Rank | BestWin | Stabil | TtP | Score |
|------|-------|--------|------|-----|-----|-----|-----|------|-------|---------|--------|-----|-------|
| ğŸ¥‡ | mistral/ministral-8b-latest | âœ… Active | 3 | ğŸŸ¢0.069 | ğŸŸ¢0.052 | ğŸŸ¢0.074 | ğŸŸ¢0.108 | ğŸŸ¢0.076 | 100.0 | 0.052 | 0.053 | 0.50 | **0.9317** |
| ğŸ¥ˆ | xai/grok-4 | âœ… Active | 3 | ğŸŸ¢0.436 | ğŸŸ¡0.565 | ğŸŸ¢0.247 | ğŸŸ¢0.106 | ğŸŸ¢0.339 | 95.7 | 0.106 | 0.255 | 0.50 | **0.8656** |
| ğŸ¥‰ | xai/grok-2-vision | âœ… Active | 3 | ğŸŸ¢0.245 | ğŸŸ¢0.335 | ğŸŸ¢0.478 | ğŸŸ¢0.459 | ğŸŸ¢0.379 | 87.0 | 0.245 | 0.193 | 0.50 | **0.8225** |
| 4 | perplexity/sonar-pro | âœ… Active | 3 | ğŸŸ¢0.288 | ğŸŸ¢0.268 | ğŸŸ¢0.317 | ğŸŸ¡0.635 | ğŸŸ¢0.377 | 91.3 | 0.268 | 0.314 | 0.50 | **0.8122** |
| 5 | openai/gpt-4.1-mini | âœ… Active | 1 | ğŸŸ¢0.223 | ğŸŸ¢0.357 | ğŸŸ¢0.431 | ğŸŸ¡0.511 | ğŸŸ¢0.380 | 82.6 | 0.337 | 0.106 | 0.50 | **0.8087** |
| 6 | anthropic/claude-3-5-haiku-latest | âœ… Active | 3 | ğŸŸ¢0.335 | ğŸŸ¢0.406 | ğŸŸ¢0.436 | ğŸŸ¡0.540 | ğŸŸ¢0.429 | 78.3 | 0.311 | 0.154 | 0.50 | **0.7856** |
| 7 | xai/grok-4.1-fast-reasoning | âœ… Active | 3 | ğŸŸ¢0.156 | ğŸŸ¢0.236 | ğŸŸ¢0.467 | ğŸ”´0.922 | ğŸŸ¢0.445 | 73.9 | 0.156 | 0.407 | 0.50 | **0.7407** |
| 8 | anthropic/claude-opus-4-5 | âœ… Active | 3 | ğŸŸ¢0.329 | ğŸŸ¢0.431 | ğŸŸ¡0.749 | ğŸŸ¡0.771 | ğŸŸ¡0.570 | 65.2 | 0.329 | 0.236 | 0.50 | **0.7144** |
| 9 | mistral/ministral-3b-latest | âœ… Active | 1 | ğŸŸ¢0.163 | ğŸŸ¢0.105 | ğŸŸ¢0.051 | ğŸ”´1.609 | ğŸŸ¢0.482 | 69.6 | 0.106 | 0.652 | 0.50 | **0.6819** |
| 10 | openai/gpt-5.2 | âœ… Active | 3 | ğŸŸ¢0.447 | ğŸŸ¡0.669 | ğŸŸ¡0.745 | ğŸŸ¡0.569 | ğŸŸ¡0.607 | 60.9 | 0.447 | 0.240 | 0.50 | **0.6785** |
| 11 | xai/grok-4-fast-non-reasoning | âœ… Active | 3 | ğŸŸ¢0.312 | ğŸŸ¢0.358 | ğŸŸ¡0.707 | ğŸ”´1.126 | ğŸŸ¡0.626 | 56.5 | 0.312 | 0.510 | 0.50 | **0.6273** |
| 12 | anthropic/claude-sonnet-4-5 | âœ… Active | 3 | ğŸŸ¢0.348 | ğŸŸ¢0.416 | ğŸ”´1.022 | ğŸ”´1.342 | ğŸŸ¡0.782 | 47.8 | 0.348 | 0.422 | 0.50 | **0.6048** |
| 13 | openai/gpt-4.1 | âœ… Active | 3 | ğŸŸ¡0.612 | ğŸŸ¡0.619 | ğŸŸ¡0.719 | ğŸ”´1.265 | ğŸ”´0.804 | 43.5 | 0.568 | 0.352 | 0.50 | **0.5684** |
| 14 | openai/gpt-5-mini | âœ… Active | 1 | ğŸŸ¢0.223 | ğŸ”´1.204 | ğŸ”´1.204 | ğŸŸ¢0.431 | ğŸŸ¡0.765 | 52.2 | 0.877 | 0.445 | 0.50 | **0.5382** |
| 15 | google/gemini-2.0-flash | âœ… Active | 3 | ğŸŸ¡0.639 | ğŸ”´0.973 | ğŸŸ¡0.781 | ğŸ”´0.973 | ğŸ”´0.842 | 34.8 | 0.639 | 0.350 | 0.50 | **0.5234** |
| 16 | google/gemini-3-pro-preview | âœ… Active | 3 | ğŸŸ¡0.646 | ğŸ”´0.999 | ğŸ”´1.081 | ğŸŸ¡0.599 | ğŸ”´0.831 | 39.1 | 0.599 | 0.515 | 0.50 | **0.5137** |
| 17 | google/gemini-2.5-flash | âœ… Active | 3 | ğŸŸ¡0.646 | ğŸ”´1.043 | ğŸ”´1.801 | ğŸŸ¡0.639 | ğŸ”´1.032 | 26.1 | 0.639 | 0.608 | 0.50 | **0.4369** |
| 18 | anthropic/claude-haiku-4-5 | âœ… Active | 2 | ğŸŸ¢0.329 | ğŸ”´1.386 | ğŸ”´1.514 | ğŸ”´1.427 | ğŸ”´1.164 | 21.7 | 0.681 | 0.505 | 0.50 | **0.4337** |
| 19 | mistral/pixtral-large-latest | âœ… Active | 3 | ğŸ”´0.847 | ğŸŸ¡0.799 | ğŸŸ¡0.776 | ğŸ”´1.474 | ğŸ”´0.974 | 30.4 | 0.776 | 0.698 | 0.50 | **0.4157** |
| 20 | anthropic/claude-3-5-sonnet-20241022 | âœ… Active | 3 | ğŸŸ¢0.431 | ğŸ”´1.386 | ğŸ”´1.609 | ğŸ”´1.897 | ğŸ”´1.331 | 8.7 | 0.431 | 0.550 | 0.50 | **0.4101** |
| 21 | anthropic/claude-3-7-sonnet-latest | âœ… Active | 3 | ğŸ”´1.081 | ğŸ”´1.631 | ğŸ”´1.461 | ğŸŸ¡0.742 | ğŸ”´1.229 | 13.0 | 0.742 | 0.468 | 0.50 | **0.3974** |
| 22 | google/gemini-2.5-pro | âœ… Active | 3 | ğŸŸ¡0.687 | ğŸ”´1.312 | ğŸ”´1.936 | ğŸ”´0.946 | ğŸ”´1.220 | 17.4 | 0.687 | 0.753 | 0.50 | **0.3659** |
| 23 | google/gemini-2.5-flash-lite | âœ… Active | 3 | ğŸŸ¡0.612 | ğŸ”´1.570 | ğŸ”´2.072 | ğŸ”´1.936 | ğŸ”´1.548 | 4.3 | 0.612 | 0.684 | 0.50 | **0.3387** |

**Legend:**

*Log loss color coding:*
- ğŸŸ¢ Good (â‰¤ 0.5) | ğŸŸ¡ OK (â‰¤ 0.8) | ğŸ”´ Poor (> 0.8)

*Column definitions:*
- `15m, 1h, 4h, 24h`: Mean log loss for that horizon across all valid rounds
- `Mean`: Arithmetic mean of the four horizon log losses
- `%Rank`: Percentile rank among all models by composite Score (higher = better)
- `BestWin`: Best rolling-window average log loss (lower = better)
- `Stabil`: Standard deviation of per-round log loss (lower = better)
- `TtP`: Time-to-pivot ratio (lower = better). *Note: With the current no-new-low ground truth system, timing data is not available; all models show TtP = 0.50.*
- `Score`: Composite metric combining rank, best window, stability, and timing (40% rank + 30% bestWinâ»Â¹ + 20% stabilâ»Â¹ + 10% TtPâ»Â¹)
- `Rnds`: Number of successful rounds (failed rounds are excluded from metrics)

## Per-Horizon Rankings (All Models)

### 15m Horizon (Top 10)

| Rank | Model | Log Loss | Status |
|------|-------|----------|--------|
| 1 | mistral/ministral-8b-latest | ğŸŸ¢0.0693 | âœ… Active |
| 2 | xai/grok-4.1-fast-reasoning | ğŸŸ¢0.1563 | âœ… Active |
| 3 | mistral/ministral-3b-latest | ğŸŸ¢0.1625 | âœ… Active |
| 4 | openai/gpt-4.1-mini | ğŸŸ¢0.2231 | âœ… Active |
| 5 | openai/gpt-5-mini | ğŸŸ¢0.2231 | âœ… Active |
| 6 | xai/grok-2-vision | ğŸŸ¢0.2447 | âœ… Active |
| 7 | perplexity/sonar-pro | ğŸŸ¢0.2877 | âœ… Active |
| 8 | xai/grok-4-fast-non-reasoning | ğŸŸ¢0.3122 | âœ… Active |
| 9 | anthropic/claude-opus-4-5 | ğŸŸ¢0.3285 | âœ… Active |
| 10 | anthropic/claude-haiku-4-5 | ğŸŸ¢0.3285 | âœ… Active |

### 1h Horizon (Top 10)

| Rank | Model | Log Loss | Status |
|------|-------|----------|--------|
| 1 | mistral/ministral-8b-latest | ğŸŸ¢0.0516 | âœ… Active |
| 2 | mistral/ministral-3b-latest | ğŸŸ¢0.1054 | âœ… Active |
| 3 | xai/grok-4.1-fast-reasoning | ğŸŸ¢0.2359 | âœ… Active |
| 4 | perplexity/sonar-pro | ğŸŸ¢0.2677 | âœ… Active |
| 5 | xai/grok-2-vision | ğŸŸ¢0.3354 | âœ… Active |
| 6 | openai/gpt-4.1-mini | ğŸŸ¢0.3567 | âœ… Active |
| 7 | xai/grok-4-fast-non-reasoning | ğŸŸ¢0.3584 | âœ… Active |
| 8 | anthropic/claude-3-5-haiku-latest | ğŸŸ¢0.4061 | âœ… Active |
| 9 | anthropic/claude-sonnet-4-5 | ğŸŸ¢0.4165 | âœ… Active |
| 10 | anthropic/claude-opus-4-5 | ğŸŸ¢0.4308 | âœ… Active |

### 4h Horizon (Top 10)

| Rank | Model | Log Loss | Status |
|------|-------|----------|--------|
| 1 | mistral/ministral-3b-latest | ğŸŸ¢0.0513 | âœ… Active |
| 2 | mistral/ministral-8b-latest | ğŸŸ¢0.0738 | âœ… Active |
| 3 | xai/grok-4 | ğŸŸ¢0.2474 | âœ… Active |
| 4 | perplexity/sonar-pro | ğŸŸ¢0.3167 | âœ… Active |
| 5 | openai/gpt-4.1-mini | ğŸŸ¢0.4308 | âœ… Active |
| 6 | anthropic/claude-3-5-haiku-latest | ğŸŸ¢0.4364 | âœ… Active |
| 7 | xai/grok-4.1-fast-reasoning | ğŸŸ¢0.4675 | âœ… Active |
| 8 | xai/grok-2-vision | ğŸŸ¢0.4785 | âœ… Active |
| 9 | xai/grok-4-fast-non-reasoning | ğŸŸ¡0.7068 | âœ… Active |
| 10 | openai/gpt-4.1 | ğŸŸ¡0.7195 | âœ… Active |

### 24h Horizon (Top 10)

| Rank | Model | Log Loss | Status |
|------|-------|----------|--------|
| 1 | xai/grok-4 | ğŸŸ¢0.1064 | âœ… Active |
| 2 | mistral/ministral-8b-latest | ğŸŸ¢0.1083 | âœ… Active |
| 3 | openai/gpt-5-mini | ğŸŸ¢0.4308 | âœ… Active |
| 4 | xai/grok-2-vision | ğŸŸ¢0.4594 | âœ… Active |
| 5 | openai/gpt-4.1-mini | ğŸŸ¡0.5108 | âœ… Active |
| 6 | anthropic/claude-3-5-haiku-latest | ğŸŸ¡0.5398 | âœ… Active |
| 7 | openai/gpt-5.2 | ğŸŸ¡0.5689 | âœ… Active |
| 8 | google/gemini-3-pro-preview | ğŸŸ¡0.5991 | âœ… Active |
| 9 | perplexity/sonar-pro | ğŸŸ¡0.6352 | âœ… Active |
| 10 | google/gemini-2.5-flash | ğŸŸ¡0.6391 | âœ… Active |

## Model Failures

*Note: Failed rounds (API errors, malformed responses) are excluded from scoring. The `Rnds` column shows successful rounds used in metric calculation.*

| Model | Failed Rounds |
|-------|---------------|
| anthropic/claude-haiku-4-5 | 1 |
| openai/gpt-4o | 1, 2, 3 |
| openai/gpt-4o-mini | 1, 2, 3 |
| openai/gpt-4.1-mini | 1, 2 |
| openai/gpt-5 | 1, 2, 3 |
| openai/gpt-5-mini | 1, 2 |
| openai/gpt-5-nano | 1, 2, 3 |
| mistral/pixtral-12b-2409 | 1, 2, 3 |
| mistral/ministral-3b-latest | 2, 3 |

---
*Auto-generated by agent_006 benchmark*