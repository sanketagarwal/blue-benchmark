# agent_006 Benchmark Results

**Symbol:** COINBASE_SPOT_BTC_USD
**Start Time:** 2026-01-05T04:04:12.620Z
**Progress:** Round 2/12 (Phase 0)
**Last Updated:** 2026-01-05T04:10:49.607Z

## Run Configuration

| Setting | Value |
|---------|-------|
| Tolerance | 0% strict undercut |
| Unique snapTimes | 12 |
| Models tested | 28 |

**Per-Horizon Configuration:**

| Horizon | Bar Size | Lookback Bars | Horizon Bars |
|---------|----------|---------------|--------------|
| 15m | 5m | 24 | 3 |
| 1h | 15m | 32 | 4 |
| 4h | 1h | 32 | 4 |
| 24h | 4h | 48 | 6 |

## Benchmark Overview

This benchmark evaluates LLMs on a **binary classification task** across 4 horizons (15m, 1h, 4h, 24h):

> For each horizon, predict whether the current reference low will hold (*no new low*) or be undercut within the forward window.

**Label definition (`noNewLow`):**
- `1` (true): Forward window low ‚â• reference low (bottom held)
- `0` (false): Forward window low < reference low (new low made)

**Horizons** share the same symbol and time but differ in bar size, lookback window, and forward prediction window.

## Methodology

### Ground Truth
- **Reference low**: Minimum low price across lookback candles
- **Forward low**: Minimum low price in the forward window (prediction horizon)
- **Label**: `y = 1` if forward low ‚â• reference low, else `y = 0`

### Probability Mapping
Models output `{ noNewLow: boolean; confidence ‚àà [0.5, 1.0] }` per horizon.
- Probability of no new low: `p = noNewLow ? confidence : (1 - confidence)`

### Scoring
- **Log loss** (primary): `LL = -(y¬∑log(p) + (1‚àíy)¬∑log(1‚àíp))`, with p clipped to [Œµ, 1‚àíŒµ]
- **Random baseline**: p=0.5 gives LL ‚âà 0.693
- **Brier score**: Used in Phase 0 sanity checks only (not shown in tables)

### Phases & Elimination
- **Phase 0 ‚Äì Sanity filter**: Disqualifies horizons where model log loss > random baseline √ó 1.1 (‚âà0.762), shows degenerate predictions (all mapped p ‚â• 0.9 or p ‚â§ 0.1), or has high extreme error rate (>20% confident wrong predictions where p > 0.8 but actual = false)
- **Phase 1 ‚Äì Percentile filter**: Retains models above performance threshold per horizon
- **Phase 2 ‚Äì Stability filter**: Evaluates consistency using rolling windows; eliminates models with no qualified horizons remaining
- **Phase 3 ‚Äì Final ranking**: Composite scoring of surviving models

> **Quick mode note:** Verification runs apply the same Phase 0‚Äì3 scoring pipeline as full benchmarks but with fewer rounds (N=3 per horizon). All metrics (log loss, best window, stability) are computed; however, with limited samples, rankings are indicative only and should not be used for final model selection.

**Status codes:**
- `‚úÖ Active`: Survived all phases with ‚â•1 qualified horizon
- `‚ùå P0`: Eliminated in Phase 0 (all horizons failed sanity checks)
- `‚ùå P2`: Eliminated in Phase 2 (no qualified horizons remaining)

## Summary

- **Active Models:** 28
- **Eliminated:** 0
- **Models with Failures:** 7

## Final Standings (Survivors)

*No models survived all elimination phases with adequate coverage.*

## All Models (Research Reference)

*Rankings are by composite score among models with adequate coverage (‚â•80% and ‚â•10 rounds).*

*No models have adequate coverage (‚â•80% and ‚â•10 rounds).*

### Not Ranked (Low Coverage or Early Stopped)

*These models had <80% coverage OR <10 effective rounds and are shown for reference only, not as competitive rankings.*

| Model | Status | Rnds | Cov | 15m | 1h | 4h | 24h | Mean | %Rank | BestWin | Stabil | TtP | Score |
|-------|--------|------|-----|-----|-----|-----|-----|------|-------|---------|--------|-----|-------|
| google/gemini-2.5-flash | ‚úÖ Active | 2 | 8/48 (17%)‚ö†Ô∏è | üü¢0.164 | üî¥0.805 | üü¢0.260 | üü¢0.197 | üü¢0.356 | 100.0 | 0.208 | 0.398 | 0.50 | 0.8393 |
| anthropic/claude-3-5-sonnet-20241022 | ‚úÖ Active | 2 | 8/48 (17%)‚ö†Ô∏è | üü¢0.394 | üü¢0.471 | üü°0.636 | üü¢0.443 | üü¢0.486 | 95.7 | 0.433 | 0.186 | 0.50 | 0.8305 |
| openai/gpt-5.2 | ‚úÖ Active | 2 | 8/48 (17%)‚ö†Ô∏è | üü¢0.301 | üü¢0.408 | üî¥0.881 | üü°0.562 | üü°0.538 | 87.0 | 0.334 | 0.221 | 0.50 | 0.8035 |
| mistral/pixtral-large-latest | ‚úÖ Active | 2 | 8/48 (17%)‚ö†Ô∏è | üü¢0.434 | üî¥1.407 | üü¢0.164 | üü¢0.134 | üü°0.535 | 91.3 | 0.124 | 0.529 | 0.50 | 0.7907 |
| anthropic/claude-3-7-sonnet-latest | ‚úÖ Active | 2 | 8/48 (17%)‚ö†Ô∏è | üü¢0.322 | üü¢0.394 | üî¥0.983 | üü°0.554 | üü°0.563 | 82.6 | 0.334 | 0.261 | 0.50 | 0.7782 |
| xai/grok-4.1-fast-reasoning | ‚úÖ Active | 2 | 8/48 (17%)‚ö†Ô∏è | üü¢0.163 | üü¢0.223 | üî¥1.204 | üü°0.714 | üü°0.576 | 78.3 | 0.183 | 0.433 | 0.50 | 0.7490 |
| xai/grok-2-vision | ‚úÖ Active | 2 | 8/48 (17%)‚ö†Ô∏è | üü¢0.223 | üü¢0.322 | üî¥1.060 | üî¥0.871 | üü°0.619 | 73.9 | 0.245 | 0.373 | 0.50 | 0.7343 |
| anthropic/claude-opus-4-5 | ‚úÖ Active | 2 | 8/48 (17%)‚ö†Ô∏è | üü¢0.180 | üü¢0.255 | üî¥1.263 | üî¥0.824 | üü°0.631 | 69.6 | 0.216 | 0.460 | 0.50 | 0.7037 |
| anthropic/claude-3-5-haiku-latest | ‚úÖ Active | 2 | 8/48 (17%)‚ö†Ô∏è | üü¢0.322 | üü¢0.327 | üî¥1.060 | üî¥0.924 | üü°0.658 | 65.2 | 0.314 | 0.355 | 0.50 | 0.6928 |
| openai/gpt-5 | ‚úÖ Active | 1 | 4/48 (8%)‚ö†Ô∏è | üü¢0.446 | üü°0.545 | üî¥0.844 | üî¥0.968 | üü°0.701 | 60.9 | 0.612 | 0.213 | 0.50 | 0.6592 |
| anthropic/claude-sonnet-4-5 | ‚úÖ Active | 2 | 8/48 (17%)‚ö†Ô∏è | üü¢0.329 | üü¢0.386 | üî¥1.177 | üî¥0.959 | üü°0.712 | 56.5 | 0.348 | 0.382 | 0.50 | 0.6476 |
| google/gemini-2.0-flash | ‚úÖ Active | 2 | 8/48 (17%)‚ö†Ô∏è | üü¢0.357 | üü°0.714 | üî¥0.916 | üî¥1.001 | üü°0.747 | 43.5 | 0.543 | 0.287 | 0.50 | 0.5851 |
| anthropic/claude-haiku-4-5 | ‚úÖ Active | 2 | 8/48 (17%)‚ö†Ô∏è | üü¢0.380 | üü°0.763 | üî¥0.834 | üî¥0.953 | üü°0.732 | 47.8 | 0.633 | 0.423 | 0.50 | 0.5617 |
| google/gemini-3-pro-preview | ‚úÖ Active | 2 | 8/48 (17%)‚ö†Ô∏è | üü¢0.051 | üü¢0.134 | üî¥1.609 | üî¥1.218 | üü°0.753 | 39.1 | 0.088 | 0.681 | 0.50 | 0.5571 |
| openai/gpt-4.1 | ‚úÖ Active | 2 | 8/48 (17%)‚ö†Ô∏è | üü¢0.278 | üü¢0.340 | üî¥1.407 | üî¥1.086 | üü°0.777 | 34.8 | 0.293 | 0.501 | 0.50 | 0.5451 |
| xai/grok-4-fast-non-reasoning | ‚úÖ Active | 2 | 8/48 (17%)‚ö†Ô∏è | üü°0.746 | üî¥0.805 | üî¥1.060 | üü¢0.297 | üü°0.727 | 52.2 | 0.611 | 0.626 | 0.50 | 0.5418 |
| openai/gpt-4.1-mini | ‚úÖ Active | 2 | 8/48 (17%)‚ö†Ô∏è | üü¢0.163 | üü¢0.322 | üî¥1.204 | üî¥1.473 | üü°0.791 | 30.4 | 0.227 | 0.598 | 0.50 | 0.5180 |
| perplexity/sonar-pro | ‚úÖ Active | 2 | 8/48 (17%)‚ö†Ô∏è | üü¢0.134 | üü¢0.193 | üî¥1.956 | üî¥1.295 | üî¥0.894 | 26.1 | 0.143 | 0.789 | 0.50 | 0.4751 |
| mistral/ministral-8b-latest | ‚úÖ Active | 2 | 8/48 (17%)‚ö†Ô∏è | üü¢0.078 | üü¢0.067 | üî¥2.009 | üî¥1.642 | üî¥0.949 | 17.4 | 0.080 | 0.897 | 0.50 | 0.4282 |
| mistral/ministral-3b-latest | ‚úÖ Active | 1 | 4/48 (8%)‚ö†Ô∏è | üü¢0.223 | üü¢0.288 | üî¥1.897 | üî¥1.204 | üî¥0.903 | 21.7 | 0.803 | 0.693 | 0.50 | 0.3780 |
| google/gemini-2.5-pro | ‚úÖ Active | 2 | 8/48 (17%)‚ö†Ô∏è | üü¢0.322 | üü°0.714 | üî¥1.263 | üî¥1.551 | üî¥0.962 | 13.0 | 0.550 | 1.039 | 0.50 | 0.3197 |
| google/gemini-2.5-flash-lite | ‚úÖ Active | 2 | 8/48 (17%)‚ö†Ô∏è | üü°0.669 | üü°0.774 | üî¥1.263 | üî¥2.100 | üî¥1.201 | 8.7 | 0.591 | 0.959 | 0.50 | 0.3043 |
| xai/grok-4 | ‚úÖ Active | 2 | 8/48 (17%)‚ö†Ô∏è | üî¥1.060 | üî¥1.295 | üî¥1.060 | üî¥2.100 | üî¥1.379 | 4.3 | 1.108 | 0.525 | 0.50 | 0.2962 |

**Legend:**

*Log loss color coding:*
- üü¢ Good (‚â§ 0.5) | üü° OK (‚â§ 0.8) | üî¥ Poor (> 0.8)

*Column definitions:*
- `Rnds`: Number of successful rounds (failed rounds are excluded from metrics)
- `Cov`: Coverage as effective/intended (percent). ‚ö†Ô∏è indicates <80% coverage or <10 effective rounds on any horizon
- `15m, 1h, 4h, 24h`: Mean log loss for that horizon across all valid rounds
- `Mean`: Arithmetic mean of the four horizon log losses
- `%Rank`: Percentile rank among all models by composite Score (higher = better)
- `BestWin`: Best rolling-window average log loss (lower = better)
- `Stabil`: Standard deviation of per-round log loss (lower = better)
- `TtP`: Time-to-pivot ratio (lower = better). *Note: With the current no-new-low ground truth system, timing data is not available; all models show TtP = 0.50.*
- `Score`: Composite metric combining rank, best window, stability, and timing (40% rank + 30% bestWin‚Åª¬π + 20% stabil‚Åª¬π + 10% TtP‚Åª¬π). *Non-rankable horizons (insufficient label diversity) are excluded from composite score calculation.*

## Per-Horizon Rankings (Top 10)

*No ranking data available.*

## Model Failures

*Note: Failed rounds (API errors, malformed responses) are excluded from scoring. The `Rnds` column shows successful rounds used in metric calculation.*

| Model | Failed Rounds |
|-------|---------------|
| openai/gpt-4o | 1, 2 |
| openai/gpt-4o-mini | 1, 2 |
| openai/gpt-5 | 2 |
| openai/gpt-5-mini | 1, 2 |
| openai/gpt-5-nano | 1, 2 |
| mistral/pixtral-12b-2409 | 1, 2 |
| mistral/ministral-3b-latest | 2 |

---
*Auto-generated by agent_006 benchmark*